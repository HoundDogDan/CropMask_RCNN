{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following setup draws from the Mask_RCNN repo by matterport and Deep Learning with Python by Chollet. \n",
    "\n",
    "https://github.com/matterport/Mask_RCNN\n",
    "https://github.com/fchollet/deep-learning-with-python-notebooks\n",
    "\n",
    "We import our packages, including maskrcnn, which needs to be installed from the github repo. \n",
    "\n",
    "We also set up our directories and paths before we organize our data into tensors. \n",
    "\n",
    "We subclass the dataset and config classes for our specific dataset\n",
    "\n",
    "Then, we train the model and test.\n",
    "\n",
    "TO DO:\n",
    "- Try to prepare the dataset and see if Keras trains succesfully, with loss decreasing at each step.\n",
    "\n",
    "- Try data augmentation: image rotation and flipping to increase our training set 6 fold\n",
    "\n",
    "- Explore data aug options in load_image_gt():  \n",
    "\n",
    "        augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.\n",
    "        For example, passing imgaug.augmenters.Fliplr(0.5) flips images\n",
    "        right/left 50% of the time.\n",
    "\n",
    "- change Config attributes to see if hyperparameters like anchor sizes (size of proposed regions that objects are located in) dramatically impact model training time and performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Import Mask RCNN\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"models\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(MODEL_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "EIGHTCHANNELDIR = os.path.join(ROOT_DIR, 'data/raw/eightchannels')\n",
    "TRAIN_DIR = os.path.join(ROOT_DIR, 'data/raw/train')\n",
    "VALIDATION_DIR = os.path.join(ROOT_DIR, 'data/raw/validation')\n",
    "TEST_DIR = os.path.join(ROOT_DIR, 'data/raw/test')\n",
    "try:\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(validation_dir)\n",
    "    os.mkdir(test_dir)\n",
    "except:\n",
    "    FileExistsError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "### Should our tensor be rank 4 [h, w, channels on and off season, instance] \n",
    "### or rank 5 [h, w, channels on season, instances, channels off season]\n",
    "def load_merge_wv2(image_id):\n",
    "    \"\"\"Load the specified wv2 os/gs image pairs and return a [H,W,8] \n",
    "    Numpy array. Channels are ordered [B, G, R, NIR, B, G, R, NIR], OS \n",
    "    first.\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    os_path = IMAGERY_DIR+'/'+image_id+'_OS_ms.tif'\n",
    "    gs_path = IMAGERY_DIR+'/'+image_id+'_GS_ms.tif'\n",
    "    os_image = skimage.io.imread(os_path)\n",
    "    gs_image = skimage.io.imread(gs_path)\n",
    "    # If has more than 4 bands, select correct bands \n",
    "    # will need to provide image config in future\n",
    "    # to programmaticaly use correct band mappings\n",
    "    if os_image.shape[-1] != 4:\n",
    "        os_image = np.dstack((os_image[:,:,1:3],os_image[:,:,4],os_image[:,:,6]))\n",
    "    if gs_image.shape[-1] != 4:\n",
    "        gs_image = np.dstack((gs_image[:,:,1:3],gs_image[:,:,4],gs_image[:,:,6]))\n",
    "    stacked_image = np.dstack((os_image, gs_image))\n",
    "    stacked_image_path = EIGHTCHANNELDIR +'/'+ image_id + '_OSGS_ms.tif'\n",
    "    return (stacked_image_path, stacked_image)\n",
    "\n",
    "IMAGERY_DIR = os.path.join(ROOT_DIR, 'data/raw/stephtest-subset/Imagery')\n",
    "GROUNDTRUTH_DIR = os.path.join(ROOT_DIR, 'data/raw/stephtest-subset/Groundtruth')\n",
    "\n",
    "# all files, including ones we don't care about\n",
    "file_ids_all = next(os.walk(IMAGERY_DIR))[2]\n",
    "# all multispectral on and off season tifs\n",
    "image_ids_all = [image_id for image_id in file_ids_all if 'ms' in image_id]\n",
    "#check for duplicates\n",
    "print(len(image_ids_all) != len(set(image_ids_all)))\n",
    "\n",
    "image_ids_gs = [image_id for image_id in image_ids_all if 'GS' in image_id]\n",
    "image_ids_os = [image_id for image_id in image_ids_all if 'OS' in image_id]\n",
    "\n",
    "#check for equality\n",
    "print(len(image_ids_os) == len(image_ids_gs))\n",
    "\n",
    "image_ids_short = [image_id[0:8] for image_id in image_ids_gs]\n",
    "image_ids_short\n",
    "\n",
    "stacked_dict = {}\n",
    "\n",
    "for imid in image_ids_short:\n",
    "    \n",
    "    path, arr = load_merge_wv2(imid)\n",
    "    stacked_dict.update({path:arr})\n",
    "    \n",
    "# trying to save 8 channel numpy array with GS, OS info. this is what matterport expects\n",
    "# BUT in mold_inputs() in https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/model.py\n",
    "# indicates that the input png/array must only have three channels...\n",
    "# We could change mold_inputs to not have this requirement and also change\n",
    "#         input_image = KL.Input(\n",
    "#            shape=[None, None, 3], name=\"input_image\")\n",
    "# on line 1841 of mrcnn/model.py but not sure if this is all the changes\n",
    "# that would be required\n",
    "# this issue indicates fix is simpler: https://github.com/matterport/Mask_RCNN/issues/314\n",
    "\n",
    "for key, val in stacked_dict.items():\n",
    "    skimage.io.imsave(key,val,plugin='tifffile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "random.seed(42)\n",
    "\n",
    "def train_test_split(imagerydir, traindir, testdir, kprop):\n",
    "    \"\"\"Splits tifs into train and test dir.\"\"\"\n",
    "    \n",
    "    image_list = next(os.walk(imagerydir))[2]\n",
    "    k = round(kprop*len(image_list))\n",
    "    test_list = random.sample(image_list,k)\n",
    "    for test in test_list:\n",
    "        shutil.copyfile(os.path.join(imagerydir,test),os.path.join(testdir,test))\n",
    "    train_list = list(set(next(os.walk(imagerydir))[2]) - set(test_list))\n",
    "    for train in train_list:\n",
    "        shutil.copyfile(os.path.join(imagerydir,train),os.path.join(traindir,train))\n",
    "    print(len(train_list))\n",
    "    print(len(test_list))\n",
    "    \n",
    "train_test_split(EIGHTCHANNELDIR,TRAIN_DIR, TEST_DIR, .1)\n",
    "\n",
    "groundtruth_list = next(os.walk(GROUNDTRUTH_DIR))[2]\n",
    "for file in groundtruth_list:\n",
    "    shutil.copyfile(os.path.join(GROUNDTRUTH_DIR,file),os.path.join(VALIDATION_DIR,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageryConfig(Config):\n",
    "    \"\"\"Configuration for training on worldview-2 imagery. \n",
    "    Will eventually want to make this a sub-class of a \n",
    "    larger Imagery class. Overrides values specific to WV2.\n",
    "    \n",
    "    Descriptive documentation for each attribute is at\n",
    "    https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/config.py\"\"\"\n",
    "    \n",
    "    def __init__(self, N):\n",
    "        \"\"\"Set values of computed attributes. Channel dimension is overriden, \n",
    "        replaced 3 with N as per this guideline: https://github.com/matterport/Mask_RCNN/issues/314\n",
    "        THERE MAY BE OTHER CODE CHANGES TO ACCOUNT FOR 3 vs N channels. See other \n",
    "        comments.\"\"\"\n",
    "        \n",
    "        # Effective batch size\n",
    "        self.BATCH_SIZE = self.IMAGES_PER_GPU * self.GPU_COUNT\n",
    "\n",
    "        # Input image size\n",
    "        if self.IMAGE_RESIZE_MODE == \"crop\":\n",
    "            self.IMAGE_SHAPE = np.array([self.IMAGE_MIN_DIM, self.IMAGE_MIN_DIM, N])\n",
    "        else:\n",
    "            self.IMAGE_SHAPE = np.array([self.IMAGE_MAX_DIM, self.IMAGE_MAX_DIM, N])\n",
    "\n",
    "        # Image meta data length\n",
    "        # See compose_image_meta() for details\n",
    "        self.IMAGE_META_SIZE = 1 + 3 + 3 + 4 + 1 + self.NUM_CLASSES\n",
    "\n",
    "    \n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"wv2-subsets\"\n",
    "\n",
    "    # Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 2\n",
    "    IMAGES_PER_GPU = 4\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # background + ag\n",
    "\n",
    "    # Use small images for faster training. Determines the image shape.\n",
    "    # From build() in model.py\n",
    "    # Exception(\"Image size must be dividable by 2 at least 6 times \"\n",
    "                       #     \"to avoid fractions when downscaling and upscaling.\"\n",
    "                       #    \"For example, use 256, 320, 384, 448, 512, ... etc. \"\n",
    "    IMAGE_MIN_DIM = 300\n",
    "    IMAGE_MAX_DIM = 300\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small.\n",
    "    # Setting Large upper scale since some fields take up nearly \n",
    "    # whole image\n",
    "    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 300)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 1000\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-3-2ddd4ca33436>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-2ddd4ca33436>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    width=width, heigh=height, bg)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "class ImageryDataset(utils.Dataset):\n",
    "    \"\"\"Generates the Imagery dataset.\"\"\"\n",
    "    \n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Load the specified image and return a [H,W,4] Numpy array.\n",
    "        Channels are ordered [B, G, R, NIR]. This is called by the \n",
    "        Keras data_generator function\n",
    "        \"\"\"\n",
    "        # Load image\n",
    "        image = skimage.io.imread(self.image_info[image_id]['path'])\n",
    "    \n",
    "        assert image.shape[-1] == 8\n",
    "        assert image.ndim == 3\n",
    "    \n",
    "        return image\n",
    "    \n",
    "    def load_wv2(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the nuclei dataset.\n",
    "\n",
    "        dataset_dir: Root directory of the dataset\n",
    "        subset: Subset to load.\n",
    "                * train: stage1_train excluding validation images\n",
    "                * val: validation images from VAL_IMAGE_IDS\n",
    "        \"\"\"\n",
    "        # Add classes. We have one class.\n",
    "        # Naming the dataset wv2, and the class agriculture\n",
    "        self.add_class(\"wv2\", 1, \"agriculture\")\n",
    "\n",
    "        # Which subset?\n",
    "        # \"test\": use TESTDIR\n",
    "        # \"train\": use TRAINDIR\n",
    "        assert subset in [\"train\", \"test\"]\n",
    "        image_dir = os.path.join(dataset_dir, subset)\n",
    "    \n",
    "        # Get image ids from directory names\n",
    "        image_paths = next(os.walk(image_dir))[2]\n",
    "\n",
    "        # Add images\n",
    "        for image_path in image_paths:\n",
    "            self.add_image(\n",
    "                \"wv2\",\n",
    "                image_id=image_path[-20:-12],\n",
    "                path=image_path)\n",
    "    \n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        # Get mask directory from image path\n",
    "        mask_dir = VALIDATION_DIR\n",
    "\n",
    "        # Read mask files from .png image\n",
    "        mask = []\n",
    "        for f in next(os.walk(mask_dir))[2]:\n",
    "            if f.endswith(\".png\"):\n",
    "                m = skimage.io.imread(os.path.join(mask_dir, f)).astype(np.bool)\n",
    "                mask.append(m)\n",
    "        mask = np.stack(mask, axis=-1)\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID, we return an array of ones\n",
    "        return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "    \n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"nucleus\":\n",
    "            return info[\"id\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = ImageryDataset()\n",
    "dataset_train.add_image()\n",
    "dataset_train.load_image()\n",
    "# dataset_train.prepare()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
