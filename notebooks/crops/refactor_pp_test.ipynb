{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "from skimage import measure\n",
    "from skimage import morphology as skim\n",
    "import skimage.io as skio\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import yaml\n",
    "import geopandas as gpd\n",
    "from rasterio import features, coords\n",
    "import rasterio\n",
    "from shapely.geometry import shape\n",
    "import matplotlib.pyplot as plt\n",
    "import gdal\n",
    "random.seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yaml(input_file):\n",
    "    \"\"\"Parse yaml file of configuration parameters.\"\"\"\n",
    "    with open(input_file, 'r') as yaml_file:\n",
    "        params = yaml.load(yaml_file)\n",
    "    return params\n",
    "\n",
    "params = parse_yaml('preprocess_config.yaml') \n",
    "\n",
    "ROOT = params['dirs']['root']\n",
    "\n",
    "DATASET = os.path.join(\n",
    "    ROOT, params['dirs']['dataset'])\n",
    "\n",
    "REORDER = os.path.join(\n",
    "    DATASET, params['dirs']['reorder'])\n",
    "\n",
    "TRAIN = os.path.join(\n",
    "    DATASET, params['dirs']['train'])\n",
    "\n",
    "TEST = os.path.join(\n",
    "    DATASET, params['dirs']['test'])\n",
    "\n",
    "GRIDDED_IMGS = os.path.join(\n",
    "    DATASET, params['dirs']['gridded_imgs'])\n",
    "\n",
    "GRIDDED_LABELS = os.path.join(\n",
    "    DATASET, params['dirs']['gridded_labels'])\n",
    "\n",
    "OPENED = os.path.join(\n",
    "    DATASET, params['dirs']['opened'])\n",
    "\n",
    "INSTANCES = os.path.join(\n",
    "    DATASET, params['dirs']['instances'])\n",
    "\n",
    "RESULTS = os.path.join(ROOT,'../',params['dirs']['results'], params['dirs']['dataset'])\n",
    "\n",
    "SOURCE_IMGS = os.path.join(\n",
    "    ROOT, params['dirs']['source_imgs'])\n",
    "\n",
    "SOURCE_LABELS = os.path.join(\n",
    "    ROOT, params['dirs']['source_labels'])\n",
    "\n",
    "NEG_BUFFERED = os.path.join(\n",
    "    DATASET, params['dirs']['neg_buffered_labels'])\n",
    "\n",
    "dirs = [DATASET, REORDER, TRAIN, TEST, GRIDDED_IMGS, GRIDDED_LABELS, OPENED, INSTANCES, NEG_BUFFERED, RESULTS]\n",
    "\n",
    "# Make directory and subdirectories\n",
    "for d in dirs:\n",
    "    pathlib.Path(d).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Change working directory to project directory\n",
    "os.chdir(dirs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yaml_to_band_index(params):\n",
    "    band_list = []\n",
    "    for i, band in enumerate(params['bands_to_include']):\n",
    "        if list(band.values())[0]== True:\n",
    "            band_list.append(i)\n",
    "    return band_list\n",
    "    \n",
    "band_indices = yaml_to_band_index(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def reorder_images(params):\n",
    "    \"\"\"Load the os, gs, or both images and subset bands. Growing\n",
    "    Season is stacked first before OS if both true.\n",
    "    \"\"\"\n",
    "    file_ids_all = next(os.walk(SOURCE_IMGS))[2]\n",
    "    band_indices = yaml_to_band_index(params)\n",
    "    image_ids_gs = sorted([image_id for image_id in file_ids_all \\\n",
    "                           if 'GS' in image_id and '.aux' not in image_id])\n",
    "    image_ids_os = sorted([image_id for image_id in file_ids_all \\\n",
    "                           if 'OS' in image_id and '.aux' not in image_id])\n",
    "    \n",
    "    if params['seasons']['GS'] and params['seasons']['OS'] == False:\n",
    "        for img_path in image_ids_gs:\n",
    "            gs_image = skio.imread(os.path.join(SOURCE_IMGS, img_path))\n",
    "            gs_image = gs_image[:,:,band_indices]\n",
    "            skio.imsave(img_path, gs_image, plugin='tifffile')\n",
    "            \n",
    "    elif params['seasons']['OS'] and params['seasons']['GS'] == False:\n",
    "        for img_path in image_ids_os:\n",
    "            os_image = skio.imread(os.path.join(SOURCE_IMGS, img_path))\n",
    "            os_image = gs_image[:,:,band_indices]\n",
    "            skio.imsave(img_path, os_image, plugin='tifffile')\n",
    "    else:\n",
    "        for gs_path, os_path in zip(image_ids_gs, image_ids_os):\n",
    "            gs_image = skio.imread(os.path.join(SOURCE_IMGS, gs_path))\n",
    "            os_image = skio.imread(os.path.join(SOURCE_IMGS, os_path))\n",
    "            gsos_image = np.dstack([gs_image[:,:,band_indices], os_image[:,:,band_indices]])\n",
    "\n",
    "            match = SequenceMatcher(None, gs_path, os_path).find_longest_match(0, len(gs_path), 0, len(os_path))\n",
    "            path = gs_path[match.b: match.b + match.size] \n",
    "            # this may need to be reworked for diff file names\n",
    "            # works best if unique ids like GS go in front of filename\n",
    "            gsos_image_path = os.path.join(REORDER, path + 'OSGS.tif')\n",
    "            skio.imsave(gsos_image_path, gsos_image, plugin='tifffile')\n",
    "            \n",
    "reorder_images(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further test from here and then continue with adjustable gridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done applying negbuff of -0.5 and filtering small labels of area less than 100.0\n"
     ]
    }
   ],
   "source": [
    "def negative_buffer_and_small_filter(params):\n",
    "    \"\"\"\n",
    "    Applies a negative buffer to wv2 labels since some are too close together and \n",
    "    produce conjoined instances when connected components is run (even after \n",
    "    erosion/dilation). This may not get rid of all conjoinments and should be adjusted.\n",
    "    It relies too on the source projection of the label file to calculate distances for\n",
    "    the negative buffer. Currently hardcodes in projections, need to look up utm pojection\n",
    "    based on spatial location somehow if I'm to extend this to work with labels anywhere.\n",
    "    \n",
    "    Returns rasterized labels that are ready to be gridded\n",
    "    \"\"\"\n",
    "    neg_buffer = float(params['label_vals']['neg_buffer'])\n",
    "    small_area_filter = float(params['label_vals']['small_area_filter'])\n",
    "    # This is a helper  used with sorted for a list of strings by specific indices in \n",
    "    # each string. Was used for a long path that ended with a file name\n",
    "    # Not needed here but may be with different source imagery and labels\n",
    "    # def takefirst_two(elem):\n",
    "    #     return int(elem[-12:-10])\n",
    "\n",
    "    items = os.listdir(SOURCE_LABELS)\n",
    "    labels = []\n",
    "    for name in items:\n",
    "        if name.endswith(\".shp\"):\n",
    "            labels.append(os.path.join(SOURCE_LABELS,name))  \n",
    "\n",
    "    shp_list = sorted(labels)\n",
    "    # need to use Source imagery for geotransform data for rasterized shapes, didn't preserve when save imgs to reorder\n",
    "    scenes = os.listdir(SOURCE_IMGS)\n",
    "    scenes = [scene for scene in scenes if 'GS' in scene]\n",
    "    img_list = []\n",
    "    for name in scenes:\n",
    "        img_list.append(os.path.join(SOURCE_IMGS,name))  \n",
    "\n",
    "    img_list = sorted(img_list)\n",
    "\n",
    "\n",
    "    for shp_path, img_path in zip(shp_list, img_list):\n",
    "        shp_frame = gpd.read_file(shp_path)\n",
    "        with rasterio.open(img_path) as rast:\n",
    "            meta = rast.meta.copy()\n",
    "            meta.update(compress=\"lzw\")\n",
    "            meta['count'] = 1\n",
    "        tifname = os.path.splitext(os.path.basename(shp_path))[0] + '.tif'\n",
    "        rasterized_name = os.path.join(NEG_BUFFERED, tifname)\n",
    "        with rasterio.open(rasterized_name, 'w+', **meta) as out:\n",
    "            out_arr = out.read(1)\n",
    "            # we get bounds to deterimine which projection to use for neg buffer\n",
    "            shp_frame.loc[0,'DN'] = 0\n",
    "            shp_frame.loc[1:,'DN'] = 1\n",
    "            maxx_bound = shp_frame.bounds.maxx.max()\n",
    "            minx_bound = shp_frame.bounds.minx.min()\n",
    "            if maxx_bound >= 30 and minx_bound>= 30:\n",
    "                shp_frame = shp_frame.to_crs({'init': 'epsg:32736'})\n",
    "                shp_frame['geometry'] = shp_frame['geometry'].buffer(neg_buffer)\n",
    "                shp_frame['Shape_Area'] = shp_frame.area\n",
    "                shp_frame = shp_frame.to_crs({'init': 'epsg:4326'})\n",
    "\n",
    "            else:\n",
    "                shp_frame = shp_frame.to_crs({'init': 'epsg:32735'})\n",
    "                shp_frame['geometry'] = shp_frame['geometry'].buffer(neg_buffer)\n",
    "                shp_frame['Shape_Area'] = shp_frame.area\n",
    "                shp_frame = shp_frame.to_crs({'init': 'epsg:4326'})\n",
    "\n",
    "            # filtering out very small fields, in meters. 100 meters area looks like a good number for now\n",
    "            shp_frame = shp_frame.loc[shp_frame.Shape_Area > small_area_filter]\n",
    "            shp_frame = shp_frame[shp_frame.DN==1] # get rid of extent polygon\n",
    "            # https://gis.stackexchange.com/questions/151339/rasterize-a-shapefile-with-geopandas-or-fiona-python#151861\n",
    "            shapes = ((geom,value) for geom, value in zip(shp_frame.geometry, shp_frame.DN))\n",
    "            burned = features.rasterize(shapes=shapes, fill=0, out=out_arr, transform=out.transform, default_value=1)\n",
    "            burned[burned < 0] = 0\n",
    "            out.write_band(1, burned) \n",
    "    print('Done applying negbuff of {negbuff} and filtering small labels of area less than {area}'.format(negbuff=neg_buffer,area=small_area_filter))\n",
    "negative_buffer_and_small_filter(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/skimage/external/tifffile/tifffile.py:1635: UserWarning: can not reshape (512, 512, 3) to (2351, 2548, 3)\n",
      "  warnings.warn(str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/skimage/external/tifffile/tifffile.py:1635: UserWarning: can not reshape (512, 512, 3) to (2301, 2525, 3)\n",
      "  warnings.warn(str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/skimage/external/tifffile/tifffile.py:1635: UserWarning: can not reshape (512, 512, 3) to (2345, 2537, 3)\n",
      "  warnings.warn(str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/skimage/external/tifffile/tifffile.py:1635: UserWarning: can not reshape (512, 512, 3) to (2296, 2541, 3)\n",
      "  warnings.warn(str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/skimage/external/tifffile/tifffile.py:1635: UserWarning: can not reshape (512, 512, 3) to (2292, 2546, 3)\n",
      "  warnings.warn(str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/skimage/external/tifffile/tifffile.py:1635: UserWarning: can not reshape (512, 512, 3) to (2325, 2551, 3)\n",
      "  warnings.warn(str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/skimage/external/tifffile/tifffile.py:1635: UserWarning: can not reshape (512, 512, 3) to (2316, 2547, 3)\n",
      "  warnings.warn(str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/skimage/external/tifffile/tifffile.py:1635: UserWarning: can not reshape (512, 512, 3) to (2277, 2519, 3)\n",
      "  warnings.warn(str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n",
      "removed scene and label, less than 0.25% good data\n"
     ]
    }
   ],
   "source": [
    "def rm_mostly_empty(scene_path, label_path):\n",
    "    '''\n",
    "    Removes a grid that is mostly (over 1/4th) empty and corrects bad no data value to 0.\n",
    "    Ignor ethe User Warning, unsure why it pops up but doesn't seem to impact the array shape\n",
    "    '''\n",
    "    usable_data_threshold = params['image_vals']['usable_thresh']\n",
    "    arr = skio.imread(scene_path)\n",
    "    arr[arr<0] = 0\n",
    "    skio.imsave(scene_path, arr)\n",
    "    pixel_count = arr.shape[0] * arr.shape[1]\n",
    "    nodata_pixel_count = (arr == 0).sum()\n",
    "    if 1-(nodata_pixel_count/pixel_count) < usable_data_threshold:\n",
    "        os.remove(scene_path)\n",
    "        os.remove(label_path)\n",
    "        print('removed scene and label, less than {}% good data'.format(usable_data_threshold))\n",
    "            \n",
    "def grid_images(params):\n",
    "    \"\"\"\n",
    "    Grids up imagery to a variable size. Filters out imagery with too little usable data.\n",
    "    appends a random unique id to each tif and label pair, appending string 'label' to the \n",
    "    mask.\n",
    "    \"\"\"\n",
    "    img_list = sorted(next(os.walk(REORDER))[2])\n",
    "    label_list = sorted(next(os.walk(NEG_BUFFERED))[2])\n",
    "\n",
    "    for img_name, label_name in zip(img_list, label_list):\n",
    "        img_path = os.path.join(REORDER, img_name)\n",
    "        label_path = os.path.join(NEG_BUFFERED, label_name)\n",
    "        #assign unique name to each gridded tif, keeping season suffix\n",
    "        #assigning int of same length as ZA0932324 naming convention\n",
    "\n",
    "        tile_size_x = params['image_vals']['grid_size']\n",
    "        tile_size_y = params['image_vals']['grid_size']\n",
    "        ds = gdal.Open(img_path)\n",
    "        band = ds.GetRasterBand(1)\n",
    "        xsize = band.XSize\n",
    "        ysize = band.YSize   \n",
    "\n",
    "        for i in range(0, xsize, tile_size_x):\n",
    "            for j in range(0, ysize, tile_size_y):\n",
    "                unique_id = str(random.randint(100000000,999999999))\n",
    "                out_path_img = os.path.join(GRIDDED_IMGS,unique_id)+ '.tif'\n",
    "                out_path_label = os.path.join(GRIDDED_LABELS,unique_id)+ '_label.tif'\n",
    "                com_string = \"gdal_translate -of GTIFF -srcwin \" + str(i)+ \", \" + str(j) + \", \" + str(tile_size_x) + \", \" + str(tile_size_y) + \" \" + str(img_path) + \" \" + str(out_path_img)\n",
    "                os.system(com_string)\n",
    "                com_string = \"gdal_translate -of GTIFF -srcwin \" + str(i)+ \", \" + str(j) + \", \" + str(tile_size_x) + \", \" + str(tile_size_y) + \" \" + str(label_path) + \" \" + str(out_path_label)\n",
    "                os.system(com_string)\n",
    "                rm_mostly_empty(out_path_img, out_path_label)\n",
    "grid_images(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_labels(params):\n",
    "    \"\"\"\n",
    "    Opens labels with kernel as defined in config.\n",
    "    \"\"\"\n",
    "    k = params['label_vals']['kernel']\n",
    "    label_list = next(os.walk(GRIDDED_LABELS))[2]\n",
    "    if params['label_vals']['open'] == True:\n",
    "        for name in label_list:\n",
    "            arr = skio.imread(os.path.join(GRIDDED_LABELS,name))\n",
    "            arr[arr < 0]=0\n",
    "            opened_path = os.path.join(OPENED,name)\n",
    "            kernel = np.ones((k,k))\n",
    "            arr = skim.binary_opening(arr, kernel)\n",
    "            arr=1*arr\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "                skio.imsave(opened_path, 1*arr)\n",
    "        \n",
    "        print('Done opening with kernel of h and w {size}'.format(size=k))\n",
    "        \n",
    "    else:\n",
    "        for name in label_list:\n",
    "            arr = skio.imread(os.path.join(GRIDDED_LABELS,name))\n",
    "            arr[arr < 0]=0\n",
    "            opened_path = os.path.join(OPENED,name)\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "                skio.imsave(opened_path, 1*arr)\n",
    "open_labels(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything up to Opening is done (though didn't plot opening looks like all files are there with right sizes'). Next need to edit move img to train folder and connected components and move masks to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_img_to_folder(params):\n",
    "    '''Moves a file with identifier pattern 760165086_OSGS.tif to a \n",
    "    folder path ZA0165086/image/ZA0165086.tif\n",
    "    Also creates a mask folder at ZA0165086/masks'''\n",
    "    image_list = os.listdir(GRIDDED_IMGS)\n",
    "    for img in image_list:\n",
    "    \n",
    "        folder_name = os.path.join(TRAIN,img[:9])\n",
    "        os.mkdir(folder_name)\n",
    "        new_path = os.path.join(folder_name, 'image')\n",
    "        mask_path = os.path.join(folder_name, 'mask')\n",
    "        os.mkdir(new_path)\n",
    "        file_path = os.path.join(GRIDDED_IMGS,img)\n",
    "        os.rename(file_path, os.path.join(new_path, img[:9]+'.tif'))\n",
    "        os.mkdir(mask_path)\n",
    "\n",
    "move_img_to_folder(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_comp(params):\n",
    "    \"\"\"\n",
    "    Extracts individual instances into their own tif files. Saves them\n",
    "    in each folder ID in train folder\n",
    "    \"\"\"\n",
    "    label_list = next(os.walk(OPENED))[2]\n",
    "    # save connected components and give each a number at end of id\n",
    "    for name in label_list:\n",
    "        arr = skio.imread(os.path.join(OPENED,name))\n",
    "        blob_labels = measure.label(arr, background=0)\n",
    "        blob_vals = np.unique(blob_labels)\n",
    "        #for imgs with no isntances, create empty mask\n",
    "        if len(blob_vals)==1:\n",
    "            img_folder = os.path.join(TRAIN,name[:9], 'image')\n",
    "            img_name = os.listdir(img_folder)[0]\n",
    "            img_path = os.path.join(img_folder, img_name)\n",
    "            arr = skio.imread(img_path)\n",
    "            mask = np.zeros_like(arr[:,:,0])\n",
    "            mask_folder = os.path.join(TRAIN,name[:9], 'mask')\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "                label_stump = os.path.splitext(os.path.basename(name))[0]\n",
    "                skio.imsave(os.path.join(mask_folder,  label_stump + '_0.tif'),mask)\n",
    "        # only run connected comp if there is at least one instance\n",
    "        for blob_val in blob_vals[blob_vals!=0]:\n",
    "            labels_copy = blob_labels.copy()\n",
    "            labels_copy[blob_labels!=blob_val] = 0\n",
    "            labels_copy[blob_labels==blob_val] = 1\n",
    "            \n",
    "            label_stump = os.path.splitext(os.path.basename(name))[0]\n",
    "            label_name = label_stump+'_'+str(blob_val)+'.tif'\n",
    "            mask_path = os.path.join(TRAIN,name[:9], 'mask')\n",
    "            label_path = os.path.join(mask_path,label_name)\n",
    "            assert labels_copy.ndim == 2\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "                skio.imsave(label_path, labels_copy)\n",
    "\n",
    "connected_comp(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(params):\n",
    "    \"\"\"Takes a sample of folder ids and copies them to a test directory\n",
    "    from a directory with all folder ids. Each sample folder contains an \n",
    "    images and corresponding masks folder.\"\"\"\n",
    "    \n",
    "    k = params['image_vals']['split']\n",
    "    sample_list = next(os.walk(TRAIN))[1]\n",
    "    k = round(k*len(sample_list))\n",
    "    test_list = random.sample(sample_list,k)\n",
    "    for test_sample in test_list:\n",
    "        shutil.copytree(os.path.join(TRAIN,test_sample),os.path.join(TEST,test_sample))\n",
    "    train_list = list(set(next(os.walk(TRAIN))[1]) - set(TEST))\n",
    "    train_df = pd.DataFrame({'train': train_list})\n",
    "    test_df = pd.DataFrame({'test': test_list})\n",
    "    train_df.to_csv(os.path.join(RESULTS, 'train_ids.csv'))\n",
    "    test_df.to_csv(os.path.join(RESULTS, 'test_ids.csv'))\n",
    "    \n",
    "train_test_split(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
