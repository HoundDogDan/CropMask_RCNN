{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "from skimage import measure\n",
    "from skimage import morphology as skim\n",
    "import skimage.io as skio\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import yaml\n",
    "import geopandas as gpd\n",
    "from rasterio import features, coords, plot\n",
    "import rasterio\n",
    "from shapely.geometry import shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yaml(input_file):\n",
    "    \"\"\"Parse yaml file of configuration parameters.\"\"\"\n",
    "    with open(input_file, 'r') as yaml_file:\n",
    "        params = yaml.load(yaml_file)\n",
    "    return params\n",
    "\n",
    "params = parse_yaml('preprocess_config.yaml') \n",
    "\n",
    "ROOT = params['dirs']['root']\n",
    "\n",
    "DATASET = os.path.join(\n",
    "    ROOT, params['dirs']['dataset'])\n",
    "\n",
    "REORDER = os.path.join(\n",
    "    DATASET, params['dirs']['reorder'])\n",
    "\n",
    "TRAIN = os.path.join(\n",
    "    DATASET, params['dirs']['train'])\n",
    "\n",
    "TEST = os.path.join(\n",
    "    DATASET, params['dirs']['test'])\n",
    "\n",
    "GRIDDED_IMGS = os.path.join(\n",
    "    DATASET, params['dirs']['gridded_imgs'])\n",
    "\n",
    "GRIDDED_LABELS = os.path.join(\n",
    "    DATASET, params['dirs']['gridded_labels'])\n",
    "\n",
    "OPENED = os.path.join(\n",
    "    DATASET, params['dirs']['opened'])\n",
    "\n",
    "INSTANCES = os.path.join(\n",
    "    DATASET, params['dirs']['instances'])\n",
    "\n",
    "RESULTS = os.path.join(ROOT,'../',params['dirs']['results'], params['dirs']['dataset'])\n",
    "\n",
    "SOURCE_IMGS = os.path.join(\n",
    "    ROOT, params['dirs']['source_imgs'])\n",
    "\n",
    "SOURCE_LABELS = os.path.join(\n",
    "    ROOT, params['dirs']['source_labels'])\n",
    "\n",
    "NEG_BUFFERED = os.path.join(\n",
    "    DATASET, params['dirs']['neg_buffered_labels'])\n",
    "\n",
    "dirs = [DATASET, REORDER, TRAIN, TEST, GRIDDED_IMGS, GRIDDED_LABELS, OPENED, INSTANCES, NEG_BUFFERED, RESULTS]\n",
    "\n",
    "# Make directory and subdirectories\n",
    "for d in dirs:\n",
    "    pathlib.Path(d).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Change working directory to project directory\n",
    "os.chdir(dirs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yaml_to_band_index(params):\n",
    "    band_list = []\n",
    "    for i, band in enumerate(params['bands_to_include']):\n",
    "        if list(band.values())[0]== True:\n",
    "            band_list.append(i)\n",
    "    return band_list\n",
    "    \n",
    "band_indices = yaml_to_band_index(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_MS_GS.tif 01_MS_OS.tif\n",
      "02_MS_GS.tif 02_MS_OS.tif\n",
      "03_MS_GS.tif 03_MS_OS.tif\n",
      "04_MS_GS.tif 04_MS_OS.tif\n",
      "05_MS_GS.tif 05_MS_OS.tif\n",
      "06_MS_GS.tif 06_MS_OS.tif\n",
      "07_MS_GS.tif 07_MS_OS.tif\n",
      "08_MS_GS.tif 08_MS_OS.tif\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def reorder_images(params):\n",
    "    \"\"\"Load the os, gs, or both images and subset bands. Growing\n",
    "    Season is stacked first before OS if both true.\n",
    "    \"\"\"\n",
    "    file_ids_all = next(os.walk(SOURCE_IMGS))[2]\n",
    "    band_indices = yaml_to_band_index(params)\n",
    "    image_ids_gs = sorted([image_id for image_id in file_ids_all \\\n",
    "                           if 'GS' in image_id and '.aux' not in image_id])\n",
    "    image_ids_os = sorted([image_id for image_id in file_ids_all \\\n",
    "                           if 'OS' in image_id and '.aux' not in image_id])\n",
    "    \n",
    "    if params['seasons']['GS'] and params['seasons']['OS'] == False:\n",
    "        for img_path in image_ids_gs:\n",
    "            gs_image = skio.imread(os.path.join(SOURCE_IMGS, img_path))\n",
    "            gs_image = gs_image[:,:,band_indices]\n",
    "            skio.imsave(gs_image_path, gs_image, plugin='tifffile')\n",
    "            \n",
    "    elif params['seasons']['OS'] and params['seasons']['GS'] == False:\n",
    "        for img_path in image_ids_os:\n",
    "            os_image = skio.imread(os.path.join(SOURCE_IMGS, img_path))\n",
    "            os_image = gs_image[:,:,band_indices]\n",
    "            skio.imsave(os_image_path, os_image, plugin='tifffile')\n",
    "    else:\n",
    "        for gs_path, os_path in zip(image_ids_gs, image_ids_os):\n",
    "            print(gs_path, os_path)\n",
    "            gs_image = skio.imread(os.path.join(SOURCE_IMGS, gs_path))\n",
    "            os_image = skio.imread(os.path.join(SOURCE_IMGS, os_path))\n",
    "            gsos_image = np.dstack([gs_image[:,:,band_indices], os_image[:,:,band_indices]])\n",
    "\n",
    "            match = SequenceMatcher(None, gs_path, os_path).find_longest_match(0, len(gs_path), 0, len(os_path))\n",
    "            path = gs_path[match.b: match.b + match.size] \n",
    "            # this may need to be reworked for diff file names\n",
    "            # works best if unique ids like GS go in front of filename\n",
    "            gsos_image_path = os.path.join(REORDER, path + 'OSGS.tif')\n",
    "            skio.imsave(gsos_image_path, gsos_image, plugin='tifffile')\n",
    "            \n",
    "reorder_images(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from rasterio import features, coords, plot\n",
    "import rasterio\n",
    "from shapely.geometry import shape\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further test from here and then continue with adjustable gridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rave/tana-crunch/waves/cropmask/data/original_steph_labels/1merge.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rave/tana-crunch/waves/cropmask/data/original_steph_labels/2merge.shp\n",
      "/home/rave/tana-crunch/waves/cropmask/data/original_steph_labels/3merge.shp\n",
      "/home/rave/tana-crunch/waves/cropmask/data/original_steph_labels/4merge.shp\n",
      "/home/rave/tana-crunch/waves/cropmask/data/original_steph_labels/5merge.shp\n",
      "/home/rave/tana-crunch/waves/cropmask/data/original_steph_labels/6merge.shp\n",
      "/home/rave/tana-crunch/waves/cropmask/data/original_steph_labels/7merge.shp\n",
      "/home/rave/tana-crunch/waves/cropmask/data/original_steph_labels/8merge.shp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def negative_buffer(params):\n",
    "    \"\"\"\n",
    "    Applies a negative buffer to wv2 labels since they are too clsoe together and \n",
    "    produce conjoined instances when connected components is performed (even after \n",
    "    erosion/dilation). This may not get rid of all conjoinments and should be adjusted.\n",
    "    It relies too on the source projection of the label file to calculate distances for\n",
    "    the negative buffer. Unsure at what scale projection would matter in calculating this \n",
    "    distance.\n",
    "    \"\"\"\n",
    "    neg_buffer = float(params['label_vals']['neg_buffer'])\n",
    "    # This is a helper  used with sorted for a list of strings by specific indices in \n",
    "    # each string. Was used for a long path that ended with a file name\n",
    "    # Not needed here but may be with different source imagery and labels\n",
    "    def takefirst_two(elem):\n",
    "        return int(elem[-12:-10])\n",
    "\n",
    "    items = os.listdir(SOURCE_LABELS)\n",
    "    labels = []\n",
    "    for name in items:\n",
    "        if name.endswith(\".shp\"):\n",
    "            labels.append(os.path.join(SOURCE_LABELS,name))  \n",
    "\n",
    "    shp_list = sorted(labels)\n",
    "\n",
    "    scenes = os.listdir(SOURCE_IMGS)\n",
    "\n",
    "    img_list = []\n",
    "    for name in scenes:\n",
    "        img_list.append(os.path.join(SOURCE_IMGS,name))  \n",
    "\n",
    "    img_list = sorted(img_list)\n",
    "\n",
    "\n",
    "    for shp_path, img_path in zip(shp_list, img_list):\n",
    "        print(shp_path)\n",
    "        shp_frame = gpd.read_file(shp_path)\n",
    "        \n",
    "        with rasterio.open(img_path) as rast:\n",
    "            meta = rast.meta.copy()\n",
    "            meta.update(compress=\"lzw\")\n",
    "            meta['count'] = 1\n",
    "            \n",
    "        rasterized_name = os.path.join(NEG_BUFFERED, os.path.basename(shp_path))\n",
    "        with rasterio.open(rasterized_name, 'w+', **meta) as out:\n",
    "            out_arr = out.read(1)\n",
    "            # this is where we create a generator of geom, value pairs to use in rasterizing\n",
    "            shp_frame['DN'].iloc[0] = 0\n",
    "            shp_frame['DN'].iloc[1:] = 1\n",
    "            maxx_bound = shp_frame.bounds.maxx.max()\n",
    "            minx_bound = shp_frame.bounds.minx.min()\n",
    "            if maxx_bound >= 30 and minx_bound>= 30:\n",
    "                shp_frame = shp_frame.to_crs({'init': 'epsg:32736'})\n",
    "                shp_frame['geometry'] = shp_frame['geometry'].buffer(neg_buffer)\n",
    "                shp_frame = shp_frame.to_crs({'init': 'epsg:4326'})\n",
    "\n",
    "            else:\n",
    "                shp_frame = shp_frame.to_crs({'init': 'epsg:32735'})\n",
    "                shp_frame['geometry'] = shp_frame['geometry'].buffer(neg_buffer)\n",
    "                shp_frame = shp_frame.to_crs({'init': 'epsg:4326'})\n",
    "\n",
    "            # hacky way of getting rid of empty geometries\n",
    "            shp_frame = shp_frame[shp_frame.Shape_Area > 9e-11]\n",
    "            shapes = ((geom,value) for geom, value in zip(shp_frame.geometry, shp_frame.DN))\n",
    "\n",
    "            burned = features.rasterize(shapes=shapes, fill=0, out=out_arr, transform=out.transform)\n",
    "            out.write_band(1, burned)\n",
    "negative_buffer(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This starts to operate on gridded wv2. above, need to move 1. 2. 3. from ntoebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(4)\n",
    "    \n",
    "    def remove_dir_folders(directory):\n",
    "        '''\n",
    "        Removes all files and sub-folders in a folder and keeps the folder.\n",
    "        '''\n",
    "    \n",
    "        folderlist = [ f for f in os.listdir(directory)]\n",
    "        for f in folderlist:\n",
    "            shutil.rmtree(os.path.join(directory,f))\n",
    "\n",
    "    def load_merge_wv2(image_id, source_dir):\n",
    "        \"\"\"Load the specified wv2 os/gs image pairs and return a [H,W,3] \n",
    "        Numpy array. Channels are ordered [B, G, R], Growing Season \n",
    "        Keeping dode comments for stacking on/off season into 8 channel tensor.\n",
    "        \"\"\"\n",
    "        # Load image\n",
    "        gs_path = source_dir+'/'+image_id+'_MS_GS.tif'\n",
    "        gs_image = skio.imread(gs_path)\n",
    "        # If has more than 4 bands, select correct bands \n",
    "        # will need to provide image config in future\n",
    "        # to programmaticaly use correct band mappings\n",
    "        if gs_image.shape[-1] != 3:\n",
    "            assert gs_image.shape == (512, 512, 8)\n",
    "            gs_image = np.dstack((gs_image[:,:,1:3],gs_image[:,:,4])) #RGB for wv2\n",
    "        #Need to functionalize all of these floating for loops\n",
    "        gs_image_path = REORDERED_DIR +'/'+ image_id + '_GS_RGB.tif'\n",
    "        assert gs_image.ndim == 3\n",
    "        gs_image[gs_image < 0]=0\n",
    "        assert gs_image.shape == (512, 512, 3)\n",
    "        skio.imsave(gs_image_path, gs_image, plugin='tifffile')\n",
    "            \n",
    "    # all files, including ones we don't care about\n",
    "    file_ids_all = next(os.walk(WV2_DIR))[2]\n",
    "    # all multispectral on and off season tifs\n",
    "    image_ids_all = [image_id for image_id in file_ids_all if 'MS' in image_id and '.aux' not in image_id]\n",
    "    #check for duplicates\n",
    "    assert len(image_ids_all) == len(set(image_ids_all))\n",
    "\n",
    "    image_ids_gs = [image_id for image_id in image_ids_all if 'GS' in image_id]\n",
    "    #image_ids_os = [image_id for image_id in image_ids_all if 'OS' in image_id]\n",
    "\n",
    "    #check for equality\n",
    "    # assert len(image_ids_os) == len(image_ids_gs)\n",
    "    # only select growing season images\n",
    "    image_ids_short = [image_id[0:9] for image_id in image_ids_gs]\n",
    "\n",
    "    for imid in image_ids_short:\n",
    "        load_merge_wv2(imid, WV2_DIR)\n",
    "\n",
    "    image_list = next(os.walk(REORDERED_DIR))[2]\n",
    "    \n",
    "    def move_img_to_folder(filename):\n",
    "        '''Moves a file with identifier pattern ZA0165086_MS_GS.tif to a \n",
    "        folder path ZA0165086/image/ZA0165086_MS_GS.tif\n",
    "        Also creates a masks folder at ZA0165086/masks'''\n",
    "        \n",
    "        folder_name = os.path.join(TRAIN_DIR,filename[:9])\n",
    "        if os.path.isdir(folder_name):\n",
    "            shutil.rmtree(folder_name)\n",
    "        os.mkdir(folder_name)\n",
    "        new_path = os.path.join(folder_name, 'image')\n",
    "        mask_path = os.path.join(folder_name, 'masks')\n",
    "        os.mkdir(new_path)\n",
    "        file_path = os.path.join(REORDERED_DIR,filename)\n",
    "        os.rename(file_path, os.path.join(new_path, filename))\n",
    "        os.mkdir(mask_path)\n",
    "\n",
    "    for img in image_list:\n",
    "        move_img_to_folder(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
