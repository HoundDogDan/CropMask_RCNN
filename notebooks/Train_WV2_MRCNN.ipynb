{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following setup draws from the Mask_RCNN repo by matterport and Deep Learning with Python by Chollet. \n",
    "\n",
    "https://github.com/matterport/Mask_RCNN\n",
    "https://github.com/fchollet/deep-learning-with-python-notebooks\n",
    "\n",
    "We import our packages, including maskrcnn, which needs to be installed from the github repo. \n",
    "\n",
    "We also set up our directories and paths before we organize our data into tensors. \n",
    "\n",
    "We subclass the dataset and config classes for our specific dataset\n",
    "\n",
    "Then, we train the model and test.\n",
    "\n",
    "TO DO:\n",
    "- Try to prepare the dataset and see if Keras trains succesfully, with loss decreasing at each step.\n",
    "\n",
    "- Try data augmentation: image rotation and flipping to increase our training set 6 fold\n",
    "\n",
    "- Explore data aug options in load_image_gt():  \n",
    "\n",
    "        augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.\n",
    "        For example, passing imgaug.augmenters.Fliplr(0.5) flips images\n",
    "        right/left 50% of the time.\n",
    "\n",
    "- change Config attributes to see if hyperparameters like anchor sizes (size of proposed regions that objects are located in) dramatically impact model training time and performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/__init__.py'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mrcnn\n",
    "mrcnn.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io as skio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from imgaug import augmenters as iaa\n",
    "%matplotlib inline\n",
    "\n",
    "# Import Mask RCNN\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import log\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/\")\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"models\")\n",
    "\n",
    "# # Local path to trained weights file\n",
    "# COCO_MODEL_PATH = os.path.join(MODEL_DIR, \"mask_rcnn_coco.h5\")\n",
    "# # Download COCO trained weights from Releases if needed\n",
    "# if not os.path.exists(COCO_MODEL_PATH):\n",
    "#     utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "TRAIN_DIR = os.path.join(ROOT_DIR, 'train')\n",
    "TEST_DIR = os.path.join(ROOT_DIR, 'test')\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'models')\n",
    "# Results directory\n",
    "# Save submission files here\n",
    "RESULTS_DIR = os.path.join(ROOT_DIR, \"results/\")\n",
    "\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "random.seed(42)\n",
    "\n",
    "def train_test_split(train_dir, test_dir, kprop):\n",
    "    \"\"\"Takes a sample of folder ids and copies them to a test directory. \n",
    "    each sample folder containes an images and corresponding masks folder\"\"\"\n",
    "    \n",
    "    sample_list = next(os.walk(train_dir))[1]\n",
    "    k = round(kprop*len(sample_list))\n",
    "    test_list = random.sample(sample_list,k)\n",
    "    for test_sample in test_list:\n",
    "        shutil.copytree(os.path.join(train_dir,test_sample),os.path.join(test_dir,test_sample))\n",
    "    train_list = list(set(next(os.walk(train_dir))[1]) - set(test_list))\n",
    "    print(len(train_list))\n",
    "    print(len(test_list))\n",
    "    return train_list, test_list\n",
    "    \n",
    "train_list, test_list = train_test_split(TRAIN_DIR, TEST_DIR, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageryConfig(Config):\n",
    "    \"\"\"Configuration for training on worldview-2 imagery. \n",
    "    Will eventually want to make this a sub-class of a \n",
    "    larger Imagery class. Overrides values specific to WV2.\n",
    "    \n",
    "    Descriptive documentation for each attribute is at\n",
    "    https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/config.py\"\"\"\n",
    "    \n",
    "    def __init__(self, N):\n",
    "        \"\"\"Set values of computed attributes. Channel dimension is overriden, \n",
    "        replaced 3 with N as per this guideline: https://github.com/matterport/Mask_RCNN/issues/314\n",
    "        THERE MAY BE OTHER CODE CHANGES TO ACCOUNT FOR 3 vs N channels. See other \n",
    "        comments.\"\"\"\n",
    "        # https://github.com/matterport/Mask_RCNN/wiki helpful for N channels\n",
    "        # Effective batch size\n",
    "        self.BATCH_SIZE = self.IMAGES_PER_GPU * self.GPU_COUNT\n",
    "        \n",
    "        IMAGE_RESIZE_MODE = \"crop\"\n",
    "        # Input image size\n",
    "        if self.IMAGE_RESIZE_MODE == \"crop\":\n",
    "            self.IMAGE_SHAPE = np.array([self.IMAGE_MIN_DIM, self.IMAGE_MIN_DIM, N])\n",
    "        else:\n",
    "            self.IMAGE_SHAPE = np.array([self.IMAGE_MAX_DIM, self.IMAGE_MAX_DIM, N])\n",
    "\n",
    "        # Image meta data length\n",
    "        # See compose_image_meta() for details\n",
    "        self.IMAGE_META_SIZE = 1 + 3 + 3 + 4 + 1 + self.NUM_CLASSES\n",
    "\n",
    "    # Image mean (RGBN RGBN)\n",
    "    # filling with N values, need to compute mean of each channel\n",
    "    MEAN_PIXEL = np.array([258.6, 345.4, 259.1,412.2,228.5,314.1,187.8,561.5])\n",
    "    \n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"wv2-gridded\"\n",
    "\n",
    "    # Batch size is 4 (GPUs * images/GPU).\n",
    "    # New parralel_model.py allows for multi-gpu\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 4\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # background + ag\n",
    "\n",
    "    # Use small images for faster training. Determines the image shape.\n",
    "    # From build() in model.py\n",
    "    # Exception(\"Image size must be dividable by 2 at least 6 times \"\n",
    "                       #     \"to avoid fractions when downscaling and upscaling.\"\n",
    "                       #    \"For example, use 256, 320, 384, 448, 512, ... etc. \"\n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small.\n",
    "    # Setting Large upper scale since some fields take up nearly \n",
    "    # whole image\n",
    "    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 300)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 200\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 1000\n",
    "    \n",
    "    #reduces the max number of field instances\n",
    "    MAX_GT_INSTANCES = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 50\n",
    "    \n",
    "    # Backbone network architecture\n",
    "    # Supported values are: resnet50, resnet101.\n",
    "    # You can also provide a callable that should have the signature\n",
    "    # of model.resnet_graph. If you do so, you need to supply a callable\n",
    "    # to COMPUTE_BACKBONE_SHAPE as well\n",
    "    BACKBONE = \"resnet50\"\n",
    "    \n",
    "    # If enabled, resizes instance masks to a smaller size to reduce\n",
    "    # memory load. Recommended when using high-resolution images.\n",
    "    USE_MINI_MASK = False\n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageryDataset(utils.Dataset):\n",
    "    \"\"\"Generates the Imagery dataset.\"\"\"\n",
    "    \n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Load the specified image and return a [H,W,8] Numpy array.\n",
    "        Channels are ordered [B, G, R, NIR]. This is called by the \n",
    "        Keras data_generator function\n",
    "        \"\"\"\n",
    "        # Load image\n",
    "        image = skio.imread(self.image_info[image_id]['path'])\n",
    "    \n",
    "        assert image.shape[-1] == 8\n",
    "        assert image.ndim == 3\n",
    "    \n",
    "        return image\n",
    "    \n",
    "    def load_wv2(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the nuclei dataset.\n",
    "\n",
    "        dataset_dir: Root directory of the dataset\n",
    "        subset: Subset to load.\n",
    "                * train: stage1_train excluding validation images\n",
    "                * val: validation images from VAL_IMAGE_IDS\n",
    "        \"\"\"\n",
    "        # Add classes. We have one class.\n",
    "        # Naming the dataset wv2, and the class agriculture\n",
    "        self.add_class(\"wv2\", 1, \"agriculture\")\n",
    "\n",
    "        assert subset in [\"train\", \"test\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "        if subset == \"test\":\n",
    "            image_ids = test_list\n",
    "        else:\n",
    "            image_ids = train_list\n",
    "        \n",
    "        # Add images\n",
    "        for image_id in image_ids:\n",
    "            self.add_image(\n",
    "                \"wv2\",\n",
    "                image_id=image_id,\n",
    "                path=os.path.join(dataset_dir, image_id, \"image/{}.tif\".format(image_id+'_OSGS_ms')))\n",
    "    \n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        # Get mask directory from image path\n",
    "        mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"masks\")\n",
    "\n",
    "        # Read mask files from .png image\n",
    "        mask = []\n",
    "        for f in next(os.walk(mask_dir))[2]:\n",
    "            if f.endswith(\".tif\"):\n",
    "                m = skio.imread(os.path.join(mask_dir, f)).astype(np.bool)\n",
    "                mask.append(m)\n",
    "        mask = np.stack(mask, axis=-1)\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID, we return an array of ones\n",
    "        return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "    \n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"field\":\n",
    "            return info[\"id\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset_dir, subset):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = ImageryDataset()\n",
    "    dataset_train.load_wv2(dataset_dir, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = ImageryDataset()\n",
    "    dataset_val.load_wv2(dataset_dir, \"test\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # Image augmentation\n",
    "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
    "    augmentation = iaa.SomeOf((0, 2), [\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.OneOf([iaa.Affine(rotate=90),\n",
    "                   iaa.Affine(rotate=180),\n",
    "                   iaa.Affine(rotate=270)]),\n",
    "        iaa.Multiply((0.8, 1.5)),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 5.0))\n",
    "    ])\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "\n",
    "    print(\"Train all layers\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=40,\n",
    "                augmentation=augmentation,\n",
    "                layers='all')\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  RLE Encoding\n",
    "############################################################\n",
    "\n",
    "def rle_encode(mask):\n",
    "    \"\"\"Encodes a mask in Run Length Encoding (RLE).\n",
    "    Returns a string of space-separated values.\n",
    "    \"\"\"\n",
    "    assert mask.ndim == 2, \"Mask must be of shape [Height, Width]\"\n",
    "    # Flatten it column wise\n",
    "    m = mask.T.flatten()\n",
    "    # Compute gradient. Equals 1 or -1 at transition points\n",
    "    g = np.diff(np.concatenate([[0], m, [0]]), n=1)\n",
    "    # 1-based indicies of transition points (where gradient != 0)\n",
    "    rle = np.where(g != 0)[0].reshape([-1, 2]) + 1\n",
    "    # Convert second index in each pair to lenth\n",
    "    rle[:, 1] = rle[:, 1] - rle[:, 0]\n",
    "    return \" \".join(map(str, rle.flatten()))\n",
    "\n",
    "def rle_decode(rle, shape):\n",
    "    \"\"\"Decodes an RLE encoded list of space separated\n",
    "    numbers and returns a binary mask.\"\"\"\n",
    "    rle = list(map(int, rle.split()))\n",
    "    rle = np.array(rle, dtype=np.int32).reshape([-1, 2])\n",
    "    rle[:, 1] += rle[:, 0]\n",
    "    rle -= 1\n",
    "    mask = np.zeros([shape[0] * shape[1]], np.bool)\n",
    "    for s, e in rle:\n",
    "        assert 0 <= s < mask.shape[0]\n",
    "        assert 1 <= e <= mask.shape[0], \"shape: {}  s {}  e {}\".format(shape, s, e)\n",
    "        mask[s:e] = 1\n",
    "    # Reshape and transpose\n",
    "    mask = mask.reshape([shape[1], shape[0]]).T\n",
    "    return mask\n",
    "\n",
    "\n",
    "def mask_to_rle(image_id, mask, scores):\n",
    "    \"Encodes instance masks to submission format.\"\n",
    "    assert mask.ndim == 3, \"Mask must be [H, W, count]\"\n",
    "    # If mask is empty, return line with image ID only\n",
    "    if mask.shape[-1] == 0:\n",
    "        return \"{},\".format(image_id)\n",
    "    # Remove mask overlaps\n",
    "    # Multiply each instance mask by its score order\n",
    "    # then take the maximum across the last dimension\n",
    "    order = np.argsort(scores)[::-1] + 1  # 1-based descending\n",
    "    mask = np.max(mask * np.reshape(order, [1, 1, -1]), -1)\n",
    "    # Loop over instance masks\n",
    "    lines = []\n",
    "    for o in order:\n",
    "        m = np.where(mask == o, 1, 0)\n",
    "        # Skip if empty\n",
    "        if m.sum() == 0.0:\n",
    "            continue\n",
    "        rle = rle_encode(m)\n",
    "        lines.append(\"{}, {}\".format(image_id, rle))\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Detection\n",
    "############################################################\n",
    "\n",
    "def detect(model, dataset_dir, subset):\n",
    "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
    "    print(\"Running on {}\".format(dataset_dir))\n",
    "\n",
    "    # Create directory\n",
    "    if not os.path.exists(RESULTS_DIR):\n",
    "        os.makedirs(RESULTS_DIR)\n",
    "    submit_dir = \"submit_{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n",
    "    submit_dir = os.path.join(RESULTS_DIR, submit_dir)\n",
    "    os.makedirs(submit_dir)\n",
    "\n",
    "    # Read dataset\n",
    "    dataset = ImageryDataset()\n",
    "    dataset.load_wv2(dataset_dir, subset)\n",
    "    dataset.prepare()\n",
    "    # Load over images\n",
    "    submission = []\n",
    "    for image_id in dataset.image_ids:\n",
    "        # Load image and run detection\n",
    "        image = dataset.load_image(image_id)\n",
    "        # Detect objects\n",
    "        r = model.detect([image], verbose=0)[0]\n",
    "        # Encode image to RLE. Returns a string of multiple lines\n",
    "        source_id = dataset.image_info[image_id][\"id\"]\n",
    "        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
    "        submission.append(rle)\n",
    "        # Save image with masks\n",
    "        visualize.display_instances(\n",
    "            image, r['rois'], r['masks'], r['class_ids'],\n",
    "            dataset.class_names, r['scores'],\n",
    "            show_bbox=False, show_mask=False,\n",
    "            title=\"Predictions\")\n",
    "        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\n",
    "\n",
    "    # Save to csv file\n",
    "    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n",
    "    file_path = os.path.join(submit_dir, \"submit.csv\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(submission)\n",
    "    print(\"Saved to \", submit_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model, trying without initial weights\n",
    "need to generate an empty mask for images without fields\n",
    "or\n",
    "toss images and masks where there are no fields (probably the worse option, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train all layers\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/models/wv2-gridded20180624T1338/mask_rcnn_wv2-gridded_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/engine/training_generator.py:44: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error processing image {'id': 'ZA0488124', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0488124/image/ZA0488124_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rankERROR:root:Error processing image {'id': 'ZA0116365', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0116365/image/ZA0116365_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rank\n",
      "\n",
      "ERROR:root:Error processing image {'id': 'ZA0493712', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0493712/image/ZA0493712_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rankERROR:root:Error processing image {'id': 'ZA0557249', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0557249/image/ZA0557249_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rank\n",
      "\n",
      "ERROR:root:Error processing image {'id': 'ZA0161611', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0161611/image/ZA0161611_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rank\n",
      "ERROR:root:Error processing image {'id': 'ZA0488132', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0488132/image/ZA0488132_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rank\n",
      "ERROR:root:Error processing image {'id': 'ZA0485502', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0485502/image/ZA0485502_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeError: sequence argument must have length equal to input rank\n",
      "ERROR:root:Error processing image {'id': 'ZA0809727', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0809727/image/ZA0809727_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rankERROR:root:Error processing image {'id': 'ZA0811581', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0811581/image/ZA0811581_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rank\n",
      "\n",
      "ERROR:root:Error processing image {'id': 'ZA0807883', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0807883/image/ZA0807883_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rank\n",
      "ERROR:root:Error processing image {'id': 'ZA0158188', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0158188/image/ZA0158188_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rank\n",
      "ERROR:root:Error processing image {'id': 'ZA0489761', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0489761/image/ZA0489761_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rank\n",
      "ERROR:root:Error processing image {'id': 'ZA0159037', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0159037/image/ZA0159037_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rank\n",
      "ERROR:root:Error processing image {'id': 'ZA0793314', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0793314/image/ZA0793314_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeError: sequence argument must have length equal to input rank\n",
      "ERROR:root:Error processing image {'id': 'ZA0806260', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0806260/image/ZA0806260_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rank\n",
      "ERROR:root:Error processing image {'id': 'ZA0807887', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0807887/image/ZA0807887_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rank\n",
      "ERROR:root:Error processing image {'id': 'ZA0116365', 'source': 'wv2', 'path': '/home/rave/tana-crunch/waves/deepimagery/data/raw/wv2/train/ZA0116365/image/ZA0116365_OSGS_ms.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1695, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1218, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 513, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 606, in zoom\n",
      "    zoom = _ni_support._normalize_sequence(zoom, input.ndim)\n",
      "  File \"/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/scipy/ndimage/_ni_support.py\", line 65, in _normalize_sequence\n",
      "    raise RuntimeError(err)\n",
      "RuntimeError: sequence argument must have length equal to input rank\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "7\n",
      "(4, 256, 256, 8)\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_image to have shape (None, None, 3) but got array with shape (256, 256, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cd5e9087bf26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model = modellib.MaskRCNN(mode=\"training\", config=config,\n\u001b[1;32m      4\u001b[0m                                   model_dir=MODEL_DIR)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mROOT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-03b570344448>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset_dir, subset)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 layers='all')\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation)\u001b[0m\n\u001b[1;32m   2326\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2329\u001b[0m         )\n\u001b[1;32m   2330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/maskrcnn/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    134\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_image to have shape (None, None, 3) but got array with shape (256, 256, 8)"
     ]
    }
   ],
   "source": [
    "\n",
    "config = ImageryConfig(8)\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=MODEL_DIR)\n",
    "train(model, ROOT_DIR, \"train\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:maskrcnn]",
   "language": "python",
   "name": "conda-env-maskrcnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
